{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Configuration ---\n",
        "ASTHMA_DATA_PATH = \"/content/drive/My Drive/Big Data Project/Data/Raw/asthma_dataset/Asthma Prevalance_Data_2020_2023.csv\"\n",
        "POLLUTANT_DATA_PATH = \"/content/drive/My Drive/Big Data Project/Data/Processed/all_pollutants_merged_inner.csv\"\n",
        "\n",
        "# Define pollutants to process\n",
        "POLLUTANTS = ['PM25', 'O3', 'NO2', 'SO2', 'CO']\n",
        "\n",
        "# Meaningful thresholds values relevant to health guidelines\n",
        "THRESHOLDS = {\n",
        "    'PM25': 9.0,  # EPA AQI \"Moderate\" 24-hour PM2.5 (ug/m3)\n",
        "    'O3': 0.070,   # EPA AQI \"Moderate\" 8-hour Ozone (ppm)\n",
        "    'NO2': 53,    # EPA 1-hour NO2 standard (ppb)\n",
        "    'SO2': 0.1,     # EPA 1-hour SO2 standard (ppb)\n",
        "    'CO': 0.35       # EPA 8-hour CO standard (ppm)\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC0x5fgjO0RQ",
        "outputId": "eb09be81-326a-4417-d576-17107388399d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load Data ---\n",
        "print(\"--- 1. Loading Data ---\")\n",
        "try:\n",
        "    df_asthma = pd.read_csv(ASTHMA_DATA_PATH)\n",
        "    print(f\"Asthma data loaded: {df_asthma.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Asthma data file not found at {ASTHMA_DATA_PATH}\")\n",
        "    df_asthma = pd.DataFrame() # Create empty to avoid downstream errors if file not found\n",
        "\n",
        "try:\n",
        "    df_pollutant_raw = pd.read_csv(POLLUTANT_DATA_PATH, low_memory=False)\n",
        "    print(f\"Pollutant data loaded: {df_pollutant_raw.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Pollutant data file not found at {POLLUTANT_DATA_PATH}\")\n",
        "    print(\"Please ensure the POLLUTANT_DATA_PATH is correct and the file exists.\")\n",
        "    df_pollutant_raw = pd.DataFrame() # Create empty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cdeMo5ZO0OH",
        "outputId": "0ccc43ee-4e6f-4d2f-ee4e-c80acc433f78"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Loading Data ---\n",
            "Asthma data loaded: (224, 4)\n",
            "Pollutant data loaded: (98351, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Prepare Pollutant Data ---\n",
        "if not df_pollutant_raw.empty:\n",
        "    print(\"\\n--- 2. Preparing Pollutant Data ---\")\n",
        "    df_pollutant = df_pollutant_raw.copy()\n",
        "\n",
        "    # Convert 'Date Local' to datetime\n",
        "    if 'Date Local' in df_pollutant.columns:\n",
        "        df_pollutant['Date Local'] = pd.to_datetime(df_pollutant['Date Local'], errors='coerce')\n",
        "        df_pollutant.dropna(subset=['Date Local'], inplace=True) # Drop rows where date conversion failed\n",
        "        df_pollutant['Year'] = df_pollutant['Date Local'].dt.year\n",
        "        df_pollutant['Month'] = df_pollutant['Date Local'].dt.month\n",
        "    else:\n",
        "        print(\"ERROR: 'Date Local' column not found in pollutant data. Cannot proceed with date-based features.\")\n",
        "        df_pollutant = pd.DataFrame() # Stop processing if no date\n",
        "\n",
        "    # Standardize 'County Name'\n",
        "    if 'County Name' in df_pollutant.columns:\n",
        "        df_pollutant['County Name'] = df_pollutant['County Name'].astype(str).str.strip().str.lower()\n",
        "    else:\n",
        "        print(\"ERROR: 'County Name' column not found in pollutant data. Cannot group by county.\")\n",
        "        df_pollutant = pd.DataFrame()\n",
        "\n",
        "    # Ensure pollutant columns are numeric\n",
        "    for p in POLLUTANTS:\n",
        "        if p in df_pollutant.columns:\n",
        "            df_pollutant[p] = pd.to_numeric(df_pollutant[p], errors='coerce')\n",
        "        else:\n",
        "            print(f\"Warning: Pollutant column '{p}' not found in pollutant data.\")\n",
        "\n",
        "    # --- Flooring Operation ---\n",
        "\n",
        "    # Define the columns that represent pollutant levels\n",
        "    POLLUTANTS_TO_FLOOR = ['PM25', 'O3', 'NO2', 'SO2', 'CO']\n",
        "\n",
        "    print(\"--- Flooring Pollutant Levels to 0 ---\")\n",
        "\n",
        "    # Check if the DataFrame exists and is not empty\n",
        "    if 'df_pollutant' in locals() and not df_pollutant.empty:\n",
        "\n",
        "        for pollutant in POLLUTANTS_TO_FLOOR:\n",
        "            if pollutant in df_pollutant.columns:\n",
        "                # Check for negative values before flooring\n",
        "                neg_count_before = (df_pollutant[pollutant] < 0).sum()\n",
        "\n",
        "                # Use clip(lower=0) to replace any value less than 0 with 0\n",
        "                df_pollutant[pollutant] = df_pollutant[pollutant].clip(lower=0)\n",
        "\n",
        "                # Check for negative values after flooring\n",
        "                neg_count_after = (df_pollutant[pollutant] < 0).sum()\n",
        "\n",
        "                print(f\"Processed '{pollutant}': Found and floored {neg_count_before} negative value(s). \"\n",
        "                      f\"Negatives remaining: {neg_count_after}.\")\n",
        "            else:\n",
        "                print(f\"Warning: Column '{pollutant}' not found, cannot floor.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Please ensure your pollutant data is loaded into a DataFrame named 'df_pollutant'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgPB_VedO0Lh",
        "outputId": "04ca0996-4d62-4a17-9629-ab27b75f5c56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2. Preparing Pollutant Data ---\n",
            "--- Flooring Pollutant Levels to 0 ---\n",
            "Processed 'PM25': Found and floored 287 negative value(s). Negatives remaining: 0.\n",
            "Processed 'O3': Found and floored 1 negative value(s). Negatives remaining: 0.\n",
            "Processed 'NO2': Found and floored 61 negative value(s). Negatives remaining: 0.\n",
            "Processed 'SO2': Found and floored 6056 negative value(s). Negatives remaining: 0.\n",
            "Processed 'CO': Found and floored 1348 negative value(s). Negatives remaining: 0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Define Seasons ---\n",
        "def get_season(month):\n",
        "    if month in [12, 1, 2]:\n",
        "        return 'Winter'\n",
        "    elif month in [3, 4, 5]:\n",
        "        return 'Spring'\n",
        "    elif month in [6, 7, 8]:\n",
        "        return 'Summer'\n",
        "    elif month in [9, 10, 11]:\n",
        "        return 'Fall'\n",
        "    return None\n",
        "\n",
        "if 'Month' in df_pollutant.columns:\n",
        "    df_pollutant['Season'] = df_pollutant['Month'].apply(get_season)"
      ],
      "metadata": {
        "id": "oz5DBllWO0JA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Feature Engineering ---\n",
        "engineered_features_list = []\n",
        "\n",
        "if not df_pollutant.empty and 'County Name' in df_pollutant.columns and 'Year' in df_pollutant.columns:\n",
        "    print(\"\\n--- 4. Engineering Features ---\")\n",
        "    grouped_annual = df_pollutant.groupby(['County Name', 'State Name', 'Year'])\n",
        "\n",
        "    # --- Define Aggregations for .agg() ---\n",
        "    aggs = {}\n",
        "\n",
        "    # Add Latitude and Longitude mean if they exist\n",
        "    if 'Latitude' in df_pollutant.columns:\n",
        "        aggs['Latitude'] = 'mean'\n",
        "    if 'Longitude' in df_pollutant.columns:\n",
        "        aggs['Longitude'] = 'mean'\n",
        "\n",
        "    # Add aggregations for each pollutant\n",
        "    for p in POLLUTANTS:\n",
        "        if p in df_pollutant.columns:\n",
        "            aggs[p] = ['mean', 'max', 'std', lambda x: x.quantile(0.75) - x.quantile(0.25)]\n",
        "\n",
        "    # --- Perform Aggregation ---\n",
        "    annual_stats = grouped_annual.agg(aggs)\n",
        "\n",
        "    # Flatten the MultiIndex columns created by .agg()\n",
        "    annual_stats.columns = ['_'.join(col).strip('_') for col in annual_stats.columns.values]\n",
        "\n",
        "    # Rename the columns for clarity and consistency\n",
        "    rename_dict = {\n",
        "        'Latitude_mean': 'Latitude',\n",
        "        'Longitude_mean': 'Longitude'\n",
        "    }\n",
        "    for p in POLLUTANTS:\n",
        "        if p in df_pollutant.columns:\n",
        "            rename_dict[f'{p}_mean'] = f'{p}_Annual_Mean'\n",
        "            rename_dict[f'{p}_max'] = f'{p}_Annual_Max'\n",
        "            rename_dict[f'{p}_std'] = f'{p}_Annual_StdDev'\n",
        "            rename_dict[f'{p}_<lambda>'] = f'{p}_Annual_IQR' # Adjust if lambda name changes\n",
        "\n",
        "    annual_stats = annual_stats.rename(columns=rename_dict)\n",
        "\n",
        "    # --- Calculate Days >/< Threshold (Separately) ---\n",
        "    days_threshold_list = []\n",
        "    for p in POLLUTANTS:\n",
        "        if p in THRESHOLDS and p in df_pollutant.columns:\n",
        "            if p == 'O3':\n",
        "                days = grouped_annual[p].apply(lambda x: (x < THRESHOLDS[p]).sum()).rename(f'{p}_Days_Below_Threshold')\n",
        "            else:\n",
        "                days = grouped_annual[p].apply(lambda x: (x > THRESHOLDS[p]).sum()).rename(f'{p}_Days_Above_Threshold')\n",
        "            days_threshold_list.append(days)\n",
        "\n",
        "    # Merge days_threshold data\n",
        "    if days_threshold_list:\n",
        "        days_threshold_df = pd.concat(days_threshold_list, axis=1)\n",
        "        annual_stats = annual_stats.merge(days_threshold_df, on=['County Name', 'State Name', 'Year'], how='left')\n",
        "\n",
        "    engineered_features_list.append(annual_stats.reset_index())\n",
        "\n",
        "    # --- Calculate Seasonal Averages (as before) ---\n",
        "    if 'Season' in df_pollutant.columns:\n",
        "        grouped_seasonal = df_pollutant.groupby(['County Name', 'State Name', 'Year', 'Season'])\n",
        "        seasonal_means_list = []\n",
        "        for p in POLLUTANTS:\n",
        "            if p in df_pollutant.columns:\n",
        "                s_mean = grouped_seasonal[p].mean().rename(f'{p}_Seasonal_Avg')\n",
        "                seasonal_means_list.append(s_mean)\n",
        "\n",
        "        if seasonal_means_list:\n",
        "            seasonal_stats_raw = pd.concat(seasonal_means_list, axis=1)\n",
        "            seasonal_stats_pivot = seasonal_stats_raw.unstack(level='Season')\n",
        "            seasonal_stats_pivot.columns = ['_'.join(col).strip() for col in seasonal_stats_pivot.columns.values]\n",
        "            engineered_features_list.append(seasonal_stats_pivot.reset_index())\n",
        "        else:\n",
        "            print(\"No seasonal pollutant data to process.\")\n",
        "    else:\n",
        "        print(\"Skipping seasonal features as 'Season' column could not be created.\")\n",
        "\n",
        "# --- 5. Combine Engineered Features ---\n",
        "df_engineered_features = pd.DataFrame()\n",
        "if engineered_features_list:\n",
        "    print(\"\\n--- 5. Combining Engineered Features ---\")\n",
        "    # Start with the first set of features (annual_stats which now includes Lat/Lon)\n",
        "    df_engineered_features = engineered_features_list[0]\n",
        "    # Merge subsequent feature sets (e.g., seasonal pivoted data)\n",
        "    for i in range(1, len(engineered_features_list)):\n",
        "        df_engineered_features = pd.merge(df_engineered_features, engineered_features_list[i],\n",
        "                                          on=['County Name', 'State Name', 'Year'], how='outer')\n",
        "    print(f\"Combined engineered features shape: {df_engineered_features.shape}\")\n",
        "    print(\"Sample of engineered features:\")\n",
        "    print(df_engineered_features.head())\n",
        "else:\n",
        "    print(\"No engineered features were created. Check pollutant data and processing steps.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2py-Z9Cecw7",
        "outputId": "ea590710-278f-4de2-813f-83d1e679bd46"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 4. Engineering Features ---\n",
            "\n",
            "--- 5. Combining Engineered Features ---\n",
            "Combined engineered features shape: (341, 50)\n",
            "Sample of engineered features:\n",
            "  County Name State Name  Year   Latitude   Longitude  PM25_Annual_Mean  \\\n",
            "0         ada      idaho  2020  43.600699 -116.347853          7.774561   \n",
            "1         ada      idaho  2021  43.600699 -116.347853          8.714545   \n",
            "2         ada      idaho  2022  43.600699 -116.347853          7.499138   \n",
            "3         ada      idaho  2023  43.600699 -116.347853          5.888073   \n",
            "4         ada      idaho  2024  43.600699 -116.347853          4.489286   \n",
            "\n",
            "   PM25_Annual_Max  PM25_Annual_StdDev  PM25_<lambda_0>  O3_Annual_Mean  ...  \\\n",
            "0             49.2            8.302082            4.975        0.027381  ...   \n",
            "1             82.6           10.878881            4.950        0.031094  ...   \n",
            "2             42.5            6.156418            6.450        0.031984  ...   \n",
            "3             25.9            4.447445            4.700        0.030272  ...   \n",
            "4             41.9            5.764994            2.975        0.034788  ...   \n",
            "\n",
            "   NO2_Seasonal_Avg_Summer  NO2_Seasonal_Avg_Winter  SO2_Seasonal_Avg_Fall  \\\n",
            "0                 7.161993                11.941740               0.223421   \n",
            "1                 8.069964                11.321667               0.287917   \n",
            "2                 7.192321                14.194643               0.193520   \n",
            "3                 6.944117                11.851058               0.349371   \n",
            "4                 3.999167                11.614112                    NaN   \n",
            "\n",
            "   SO2_Seasonal_Avg_Spring  SO2_Seasonal_Avg_Summer  SO2_Seasonal_Avg_Winter  \\\n",
            "0                 0.254821                 0.177016                 0.238719   \n",
            "1                 0.234048                 0.237121                 0.239123   \n",
            "2                 0.226711                 0.419388                 0.103321   \n",
            "3                 0.175495                 0.262302                 0.191211   \n",
            "4                 0.268675                 0.230114                 0.275000   \n",
            "\n",
            "   CO_Seasonal_Avg_Fall  CO_Seasonal_Avg_Spring  CO_Seasonal_Avg_Summer  \\\n",
            "0              0.255222                0.161795                0.156476   \n",
            "1              0.244500                0.144686                0.224145   \n",
            "2              0.247673                0.156461                0.148341   \n",
            "3              0.208184                0.169992                0.171614   \n",
            "4                   NaN                0.143499                0.107709   \n",
            "\n",
            "   CO_Seasonal_Avg_Winter  \n",
            "0                0.211067  \n",
            "1                0.212074  \n",
            "2                0.224621  \n",
            "3                0.225276  \n",
            "4                0.208634  \n",
            "\n",
            "[5 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Merge with Asthma Data ---\n",
        "df_final_asthma_gnn = None\n",
        "\n",
        "if not df_asthma.empty and not df_engineered_features.empty:\n",
        "    print(\"\\n--- 6. Merging Engineered Features with Asthma Data ---\")\n",
        "\n",
        "    # Standardize 'County Name' in asthma data for merging\n",
        "    if 'County Name' in df_asthma.columns:\n",
        "        df_asthma['County Name'] = df_asthma['County Name'].astype(str).str.strip().str.lower()\n",
        "    else:\n",
        "        print(\"ERROR: 'County Name' not in asthma data. Cannot merge.\")\n",
        "        df_asthma = pd.DataFrame() # Make it empty to skip merge\n",
        "\n",
        "    if 'Year' not in df_asthma.columns:\n",
        "        print(\"ERROR: 'Year' not in asthma data. Cannot merge.\")\n",
        "        df_asthma = pd.DataFrame() # Make it empty to skip merge\n",
        "\n",
        "    # Only attempt merge if required columns are present in asthma data\n",
        "    if not df_asthma.empty:\n",
        "\n",
        "        # --- Handle potential column conflicts BEFORE merging ---\n",
        "        # Get columns from engineered_features, excluding keys to avoid duplication issues\n",
        "        features_to_add = df_engineered_features.drop(columns=['County Name', 'Year'], errors='ignore')\n",
        "\n",
        "        # If 'State Name' exists in both, keep the one from engineered_features\n",
        "        if 'State Name' in df_asthma.columns and 'State Name' in features_to_add.columns:\n",
        "             df_asthma = df_asthma.drop(columns=['State Name'])\n",
        "\n",
        "        # If Lat/Lon exist, drop them to prefer Eng_Latitude/Eng_Longitude\n",
        "        df_asthma = df_asthma.drop(columns=['Latitude', 'Longitude'], errors='ignore')\n",
        "\n",
        "        # Perform a left merge to keep all asthma records\n",
        "        df_final_asthma_gnn = pd.merge(df_asthma, df_engineered_features,\n",
        "                                       on=['County Name', 'Year'],\n",
        "                                       how='left')\n",
        "\n",
        "        print(f\"Final merged data shape for GNN: {df_final_asthma_gnn.shape}\")\n",
        "        print(\"Sample of final merged data:\")\n",
        "        print(df_final_asthma_gnn.head())\n",
        "\n",
        "        # Save this to a new CSV\n",
        "        output_gnn_data_path = \"/content/drive/My Drive/Big Data Project/Data/Processed/asthma_data_with_engineered_pollutants.csv\"\n",
        "        df_final_asthma_gnn.to_csv(output_gnn_data_path, index=False)\n",
        "        print(f\"\\nSaved final data to: {output_gnn_data_path}\")\n",
        "    else:\n",
        "        print(\"Skipping merge due to missing key columns in asthma data.\")\n",
        "\n",
        "elif df_asthma.empty:\n",
        "    print(\"Asthma data is empty. Cannot merge.\")\n",
        "\n",
        "else: # df_engineered_features is empty\n",
        "    print(\"No engineered features to merge. The original asthma data remains unchanged.\")\n",
        "    df_final_asthma_gnn = df_asthma\n",
        "\n",
        "if df_final_asthma_gnn is not None:\n",
        "    print(\"\\nFinal columns in the dataset for GNN:\")\n",
        "    print(df_final_asthma_gnn.columns.tolist())\n",
        "else:\n",
        "    print(\"\\nFinal GNN dataset could not be created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSTgDBllgBN8",
        "outputId": "23b31285-c933-47e0-d6e4-1dabb10147cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 6. Merging Engineered Features with Asthma Data ---\n",
            "Final merged data shape for GNN: (224, 52)\n",
            "Sample of final merged data:\n",
            "  County Name  Year  Age-adjusted rate per 10,000  Number of cases  \\\n",
            "0     alameda  2020                         27.32             4274   \n",
            "1      amador  2020                         28.89              103   \n",
            "2       butte  2020                         23.98              473   \n",
            "3   calaveras  2020                         29.14              111   \n",
            "4      colusa  2020                         25.45               49   \n",
            "\n",
            "   State Name   Latitude   Longitude  PM25_Annual_Mean  PM25_Annual_Max  \\\n",
            "0  california  37.814781 -122.282347         10.154739       159.708333   \n",
            "1         NaN        NaN         NaN               NaN              NaN   \n",
            "2         NaN        NaN         NaN               NaN              NaN   \n",
            "3         NaN        NaN         NaN               NaN              NaN   \n",
            "4         NaN        NaN         NaN               NaN              NaN   \n",
            "\n",
            "   PM25_Annual_StdDev  ...  NO2_Seasonal_Avg_Summer  NO2_Seasonal_Avg_Winter  \\\n",
            "0           15.160527  ...                 6.643137                17.559966   \n",
            "1                 NaN  ...                      NaN                      NaN   \n",
            "2                 NaN  ...                      NaN                      NaN   \n",
            "3                 NaN  ...                      NaN                      NaN   \n",
            "4                 NaN  ...                      NaN                      NaN   \n",
            "\n",
            "   SO2_Seasonal_Avg_Fall  SO2_Seasonal_Avg_Spring  SO2_Seasonal_Avg_Summer  \\\n",
            "0               0.423878                 0.194244                 0.060751   \n",
            "1                    NaN                      NaN                      NaN   \n",
            "2                    NaN                      NaN                      NaN   \n",
            "3                    NaN                      NaN                      NaN   \n",
            "4                    NaN                      NaN                      NaN   \n",
            "\n",
            "   SO2_Seasonal_Avg_Winter  CO_Seasonal_Avg_Fall  CO_Seasonal_Avg_Spring  \\\n",
            "0                 0.456991              0.550846                0.346113   \n",
            "1                      NaN                   NaN                     NaN   \n",
            "2                      NaN                   NaN                     NaN   \n",
            "3                      NaN                   NaN                     NaN   \n",
            "4                      NaN                   NaN                     NaN   \n",
            "\n",
            "   CO_Seasonal_Avg_Summer  CO_Seasonal_Avg_Winter  \n",
            "0                0.353915                0.569187  \n",
            "1                     NaN                     NaN  \n",
            "2                     NaN                     NaN  \n",
            "3                     NaN                     NaN  \n",
            "4                     NaN                     NaN  \n",
            "\n",
            "[5 rows x 52 columns]\n",
            "\n",
            "Saved final data to: /content/drive/My Drive/Big Data Project/Data/Processed/asthma_data_with_engineered_pollutants.csv\n",
            "\n",
            "Final columns in the dataset for GNN:\n",
            "['County Name', 'Year', 'Age-adjusted rate per 10,000', 'Number of cases', 'State Name', 'Latitude', 'Longitude', 'PM25_Annual_Mean', 'PM25_Annual_Max', 'PM25_Annual_StdDev', 'PM25_<lambda_0>', 'O3_Annual_Mean', 'O3_Annual_Max', 'O3_Annual_StdDev', 'O3_<lambda_0>', 'NO2_Annual_Mean', 'NO2_Annual_Max', 'NO2_Annual_StdDev', 'NO2_<lambda_0>', 'SO2_Annual_Mean', 'SO2_Annual_Max', 'SO2_Annual_StdDev', 'SO2_<lambda_0>', 'CO_Annual_Mean', 'CO_Annual_Max', 'CO_Annual_StdDev', 'CO_<lambda_0>', 'PM25_Days_Above_Threshold', 'O3_Days_Below_Threshold', 'NO2_Days_Above_Threshold', 'SO2_Days_Above_Threshold', 'CO_Days_Above_Threshold', 'PM25_Seasonal_Avg_Fall', 'PM25_Seasonal_Avg_Spring', 'PM25_Seasonal_Avg_Summer', 'PM25_Seasonal_Avg_Winter', 'O3_Seasonal_Avg_Fall', 'O3_Seasonal_Avg_Spring', 'O3_Seasonal_Avg_Summer', 'O3_Seasonal_Avg_Winter', 'NO2_Seasonal_Avg_Fall', 'NO2_Seasonal_Avg_Spring', 'NO2_Seasonal_Avg_Summer', 'NO2_Seasonal_Avg_Winter', 'SO2_Seasonal_Avg_Fall', 'SO2_Seasonal_Avg_Spring', 'SO2_Seasonal_Avg_Summer', 'SO2_Seasonal_Avg_Winter', 'CO_Seasonal_Avg_Fall', 'CO_Seasonal_Avg_Spring', 'CO_Seasonal_Avg_Summer', 'CO_Seasonal_Avg_Winter']\n"
          ]
        }
      ]
    }
  ]
}